!ls /kaggle/input/titanic

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score

# read dataset
train = pd.read_csv("/kaggle/input/titanic/train.csv")
features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
X = train[features].copy()
y = train["Survived"]

# data preprocessing
X["Age"] = X["Age"].fillna(X["Age"].median())
X["Embarked"] = X["Embarked"].fillna(X["Embarked"].mode()[0])

X["Sex"] = LabelEncoder().fit_transform(X["Sex"])
X["Embarked"] = LabelEncoder().fit_transform(X["Embarked"])

# split training dataset and testing dataset
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# train initial model
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)
print("initial accuracy:", accuracy_score(y_val, model.predict(X_val)))

# grid search
param_grid = {
    "max_depth": [3, 5, 7, 10, None],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "criterion": ["gini", "entropy"]
}
grid = GridSearchCV(DecisionTreeClassifier(random_state=42),
                    param_grid, cv=5, scoring="accuracy")
grid.fit(X_train, y_train)

best_model = grid.best_estimator_
print("best paramater", grid.best_params_)
print("best score:", grid.best_score_)
print("accuracy:", accuracy_score(y_val, best_model.predict(X_val)))

# create decision tree
plt.figure(figsize=(20,10))
plot_tree(best_model, feature_names=features, class_names=["Not Survived", "Survived"], filled=True)
plt.show()

from sklearn.model_selection import cross_val_score

# five-fold cross validation
scores = cross_val_score(best_model, X, y, cv=5, scoring='accuracy')

print("classification accuracy:", scores)
print("average classification accuracy:", scores.mean())

from sklearn.ensemble import RandomForestClassifier

best_rf = RandomForestClassifier(
    n_estimators=200,        # number of trees
    max_depth=7,             # max depth
    min_samples_split=5,     # min splite samples
    min_samples_leaf=2,      # min leaf samples
    random_state=42
)

scores = cross_val_score(best_rf, X, y, cv=5, scoring='accuracy')

print("classification accuracy::", scores)
print("average classification accuracy:", scores.mean())

